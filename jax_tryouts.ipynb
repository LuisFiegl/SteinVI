{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12lui\\AppData\\Local\\Temp\\ipykernel_6568\\2169528782.py:2: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  df_train = df[\"2000-01-01\":\"2017-01-01\"]\n",
      "C:\\Users\\12lui\\AppData\\Local\\Temp\\ipykernel_6568\\2169528782.py:3: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  df_test = df[\"2017-01-01\":\"2019-01-01\"]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"grouped_df.pkl\")\n",
    "df_train = df[\"2000-01-01\":\"2017-01-01\"]\n",
    "df_test = df[\"2017-01-01\":\"2019-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(1155)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(512)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(1)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def log_sigmoid(x):\n",
    "    return -jnp.log(1 + jnp.exp(-x))\n",
    "\n",
    "def binary_cross_entropy(logits, labels):\n",
    "    logprobs = log_sigmoid(logits) * (1 - labels) + (log_sigmoid(logits) - logits) * labels\n",
    "    return -jnp.mean(logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = optax.adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "key = random.PRNGKey(0)\n",
    "initial_params = BayesianNN().init(key, jnp.ones((1, df_train.shape[1]-1)))\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=BayesianNN().apply,\n",
    "    params=initial_params,\n",
    "    tx=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn(params, batch[\"input\"])\n",
    "        loss = binary_cross_entropy(logits, batch[\"label\"])\n",
    "        return loss\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grad = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grad)\n",
    "    return state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training state\n",
    "rng = jax.random.PRNGKey(0)\n",
    "batch_size = 64\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(df_train), batch_size):\n",
    "        batch_input = df_train.iloc[i:i + batch_size, :-1].values\n",
    "        batch_label = df_train.iloc[i:i + batch_size, -1].values\n",
    "        batch = {\"input\": batch_input, \"label\": batch_label}\n",
    "        state, loss = train_step(state, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(params, batch):\n",
    "    inputs, targets = batch\n",
    "    logits = state.apply_fn(params, inputs)\n",
    "    predicted = jnp.round(jax.nn.sigmoid(logits))\n",
    "    return jnp.mean(predicted == targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': array([[ 1.1285163 ,  0.58350284,  0.59466237, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.21005125,  1.46029109,  0.59114704, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.24997031, -0.29574433, -0.2858963 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.52457258,  1.83987033,  1.25098509, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.76535472, -0.53603427, -0.2658714 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.52585318,  0.83832734,  1.00361173, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " 'label': array([0, 0, 0, ..., 1, 1, 1], dtype=uint8)}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\12lui\\Desktop\\python1\\transformer_trading\\jax_tryouts.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_batch_label \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39miloc[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_batch \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: test_batch_input, \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: test_batch_label}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_accuracy \u001b[39m=\u001b[39m accuracy(state\u001b[39m.\u001b[39;49mparams, test_batch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest accuracy:\u001b[39m\u001b[39m'\u001b[39m, test_accuracy)\n",
      "\u001b[1;32mc:\\Users\\12lui\\Desktop\\python1\\transformer_trading\\jax_tryouts.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccuracy\u001b[39m(params, batch):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     inputs, targets \u001b[39m=\u001b[39m batch\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     logits \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39;49mapply_fn(params, inputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     predicted \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mround(jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msigmoid(logits))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mmean(predicted \u001b[39m==\u001b[39m targets)\n",
      "    \u001b[1;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\12lui\\Desktop\\python1\\transformer_trading\\jax_tryouts.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m@nn\u001b[39m\u001b[39m.\u001b[39mcompact\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mDense(\u001b[39m1155\u001b[39;49m)(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12lui/Desktop/python1/transformer_trading/jax_tryouts.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDense(\u001b[39m512\u001b[39m)(x)\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\12lui\\anaconda3\\envs\\NewTrading\\lib\\site-packages\\flax\\linen\\linear.py:238\u001b[0m, in \u001b[0;36mDense.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39m@compact\u001b[39m\n\u001b[0;32m    226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inputs: Array) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[0;32m    227\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \n\u001b[0;32m    229\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39m    The transformed input.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m    235\u001b[0m   kernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\n\u001b[0;32m    236\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    237\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_init,\n\u001b[1;32m--> 238\u001b[0m       (jnp\u001b[39m.\u001b[39;49mshape(inputs)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures),\n\u001b[0;32m    239\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_dtype,\n\u001b[0;32m    240\u001b[0m   )\n\u001b[0;32m    241\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[0;32m    242\u001b[0m     bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\n\u001b[0;32m    243\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_init, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures,), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_dtype\n\u001b[0;32m    244\u001b[0m     )\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "test_batch_input = df_test.iloc[:, :-1].values\n",
    "test_batch_label = df_test.iloc[:, -1].values\n",
    "\n",
    "test_batch = {\"input\": test_batch_input, \"label\": test_batch_label}\n",
    "test_accuracy = accuracy(state.params, test_batch)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewTrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
